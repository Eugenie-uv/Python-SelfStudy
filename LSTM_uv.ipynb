{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "通过姓氏来预测性别\n",
    "\n",
    "\n",
    "#### 源文章\n",
    "https://towardsdatascience.com/choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras-f8e9ed76f046\n",
    "\n",
    "#### 源代码\n",
    "https://github.com/R4h4/Firstname_gender_prediction/blob/master/Article_Gender_Prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyou/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the name.csv\n",
    "# filepath = 'd:/AS_Data/temp/name_test.csv'\n",
    "filepath = 'name_test.csv'\n",
    "max_rows = 500000 # Reduction due to memory limitations\n",
    "\n",
    "df = (pd.read_csv(filepath, usecols=['first_name', 'gender'])\n",
    "        .dropna(subset=['first_name', 'gender'])\n",
    "        .assign(first_name = lambda x: x.first_name.str.strip())\n",
    "        .head(max_rows))\n",
    "\n",
    "# In the case of a middle name, we will simply use the first name only\n",
    "df['first_firstname'] = df['first_name'].apply(lambda x: str(x).split(' ', 1)[0])\n",
    "\n",
    "# Sometimes people only but the first letter of their name into the field, so we drop all name where len <3\n",
    "df.drop(df[df['first_firstname'].str.len() < 3].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input vector will have the shape 15x30.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "# convert every (first) name into a vector using One-Hot Encoding\n",
    "\n",
    "# Parameters\n",
    "predictor_col = 'first_firstname'\n",
    "result_col = 'gender'\n",
    "\n",
    "accepted_chars = 'abcdefghijklmnopqrstuvwxyzöäü-'\n",
    "\n",
    "word_vec_length = min(df[predictor_col].apply(len).max(), 25) \n",
    "#Length of the input vector\n",
    "\n",
    "char_vec_length = len(accepted_chars) \n",
    "#Length of the character vector\n",
    "\n",
    "output_labels = 2 #Number of output labels\n",
    "\n",
    "print(f\"The input vector will have the shape {word_vec_length}x{char_vec_length}.\")\n",
    "#Out: The input vector will have the shape 23x30.\n",
    "\n",
    "# Define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(accepted_chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(accepted_chars))\n",
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，\n",
    "#同时列出数据和数据下标\n",
    "#eg. enumerate(sequence, [start=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# char_to_int\n",
    "# int_to_char\n",
    "# for i,c in enumerate(accepted_chars):\n",
    "#     print(i,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all non accepted characters\n",
    "# 全部字母转为小写\n",
    "def normalize(line):\n",
    "    return [c.lower() for c in line if c.lower() in accepted_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of n lists with n = word_vec_length\n",
    "# OneHot编码姓名\n",
    "def name_encoding(name):\n",
    "\n",
    "    # Encode input data to int, e.g. a->1, z->26\n",
    "    integer_encoded = [char_to_int[char] for i, char in enumerate(name) if i < word_vec_length]\n",
    "    \n",
    "    # Start one-hot-encoding\n",
    "    onehot_encoded = list()\n",
    "    \n",
    "    for value in integer_encoded:\n",
    "        # create a list of n zeros, where n is equal to the number of accepted characters\n",
    "        letter = [0 for _ in range(char_vec_length)]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "        \n",
    "    # Fill up list to the max length. Lists need do have equal length to be able to convert it into an array\n",
    "    for _ in range(word_vec_length - len(name)):\n",
    "        onehot_encoded.append([0 for _ in range(char_vec_length)])\n",
    "        \n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the output labels\n",
    "# OneHot编码标签：男性为[1,0], 女性为[0,1]\n",
    "def lable_encoding(gender_series):\n",
    "    labels = np.empty((0, 2))\n",
    "    for i in gender_series:\n",
    "        if i == 'M':\n",
    "            labels = np.append(labels, [[1,0]], axis=0)\n",
    "        else:\n",
    "            labels = np.append(labels, [[0,1]], axis=0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input vector will have the shape 15x30.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Split dataset in 60% train, 20% test and 20% validation\n",
    "train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "# Convert both the input names as well as the output lables into the discussed machine readable vector format\n",
    "train_x =  np.asarray([np.asarray(name_encoding(normalize(name))) for name in train[predictor_col]])\n",
    "train_y = lable_encoding(train.gender)\n",
    "\n",
    "validate_x = np.asarray([name_encoding(normalize(name)) for name in validate[predictor_col]])\n",
    "validate_y = lable_encoding(validate.gender)\n",
    "\n",
    "test_x = np.asarray([name_encoding(normalize(name)) for name in test[predictor_col]])\n",
    "test_y = lable_encoding(test.gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of hidden nodes is 300.\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes = int(2/3 * (word_vec_length * char_vec_length))\n",
    "print(f\"The number of hidden nodes is {hidden_nodes}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model ...\n"
     ]
    }
   ],
   "source": [
    "print('Building the model ...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_nodes, return_sequences=False, input_shape=(word_vec_length, char_vec_length)))\n",
    "model.add(Dropout(0.2))\n",
    "#Dropout 层，它会在训练阶段忽略随机选定的某些神经元的输出，以此减轻单独神经元对某些特定权重的敏感性，\n",
    "#这将在一定程度上防止模型出现过拟合的现象\n",
    "#通常将 deopout_rate 设置为 20%\n",
    "model.add(Dense(units=output_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 517 samples, validate on 173 samples\n",
      "Epoch 1/10\n",
      "517/517 [==============================] - 2s 3ms/step - loss: 0.6911 - acc: 0.8104 - val_loss: 0.6635 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "517/517 [==============================] - 0s 909us/step - loss: 0.6645 - acc: 1.0000 - val_loss: 0.6296 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "517/517 [==============================] - 0s 938us/step - loss: 0.6314 - acc: 1.0000 - val_loss: 0.5789 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "517/517 [==============================] - 0s 930us/step - loss: 0.5823 - acc: 1.0000 - val_loss: 0.4988 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.5028 - acc: 1.0000 - val_loss: 0.3739 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "517/517 [==============================] - 1s 971us/step - loss: 0.3797 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "517/517 [==============================] - 1s 971us/step - loss: 0.2084 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "517/517 [==============================] - 1s 968us/step - loss: 0.0531 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "517/517 [==============================] - 0s 942us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.8688e-05 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "517/517 [==============================] - 0s 922us/step - loss: 2.1715e-05 - acc: 1.0000 - val_loss: 2.5461e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117a41be0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "model.fit(train_x, train_y, \n",
    "          batch_size=batch_size, \n",
    "          epochs =10, \n",
    "          validation_data=(validate_x, validate_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>first_firstname</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Addicks</td>\n",
       "      <td>M</td>\n",
       "      <td>Addicks</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Ebel</td>\n",
       "      <td>M</td>\n",
       "      <td>Ebel</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Eberhardt</td>\n",
       "      <td>M</td>\n",
       "      <td>Eberhardt</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Stoiber</td>\n",
       "      <td>M</td>\n",
       "      <td>Stoiber</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Engelhardt</td>\n",
       "      <td>M</td>\n",
       "      <td>Engelhardt</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_name gender first_firstname predicted_gender\n",
       "290     Addicks      M         Addicks                F\n",
       "371        Ebel      M            Ebel                F\n",
       "374   Eberhardt      M       Eberhardt                F\n",
       "754     Stoiber      M         Stoiber                F\n",
       "452  Engelhardt      M      Engelhardt                F"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate['predicted_gender'] = ['M' if prediction[0] > prediction[1] else 'F' for prediction in model.predict(validate_x)]\n",
    "\n",
    "# 预测错误的序号\n",
    "validate[validate['gender']!=validate['predicted_gender']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
